def process_segment(lines, letter_type, esperanto_to_x, x_to_jijofu, x_to_hat, replacements_1, replacements_2):
    # 文字列のリストを結合してから置換処理を実行
    segment = '\n'.join(lines)
    segment = multiple_replace(segment, esperanto_to_x)
    segment = multi_smart_replace(segment, replacements_1)
    segment = multi_smart_replace(segment, replacements_2)

    if letter_type == 1:
        segment = multiple_replace(segment, x_to_jijofu)
    elif letter_type == 2:
        segment = multiple_replace(segment, x_to_hat)

    return segment

def parallel_process(text, num_processes, letter_type, esperanto_to_x, x_to_jijofu, x_to_hat, replacements_1, replacements_2):
    # テキストを行で分割
    lines = text.split('\n')
    num_lines = len(lines)
    lines_per_process = num_lines // num_processes

    # 各プロセスに割り当てる行のリストを決定
    ranges = [(i * lines_per_process, (i + 1) * lines_per_process) for i in range(num_processes)]
    ranges[-1] = (ranges[-1][0], num_lines)  # 最後のプロセスが残り全てを処理

    with multiprocessing.Pool(processes=num_processes) as pool:
        # 並列処理を実行
        results = pool.starmap(process_segment, [(lines[start:end], letter_type, esperanto_to_x, x_to_jijofu, x_to_hat, replacements_1, replacements_2) for start, end in ranges])

    # 結果を結合
    return '\n'.join(result for result in results)

# テキストの読み込み
with open('例文(input).txt', 'r', encoding='utf-8') as f:
    text = f.read()###文字数が増えれば増えるほど、処理時間がプロセス数(CPUの個数)に反比例するようになる。

# 置換辞書を準備
replacements_1 = {key: sorted_vocab[key][0] for key in sorted_keys}
replacements_2 = {sorted_vocab_copy[key][0]: key for key in sorted_keys if '&#' in sorted_vocab_copy[key][0]}

# 並列処理の実行
processed_text = parallel_process(text, 8, letter_type, esperanto_to_x, x_to_jijofu, x_to_hat, replacements_1, replacements_2)

# 結果をファイルに書き込み
with open('語根に対応する漢字によって置換された文章(output).html', 'w', encoding='utf-8') as f:
    f.write(processed_text)
